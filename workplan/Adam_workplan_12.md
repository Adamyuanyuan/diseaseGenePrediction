#<center>工作报告_12</center>

######<center>2015.01.21</center>


#### 一、近期工作————使用RBR训练各种数据组合

近期调整了数据格式，将空值设置成 100000000000000000000 并且对其相关基因的属性，即可成功使用RBR进行训练，并进行分析，结果如下

###### 1. 使用RBR训练mouse human eye 的三个原始数据

| tools| top 100 | 200 | 300 | 400 | 500 | 600 | 700 | 800 | 900 | 1000 | 1100 | 1200 | 1300 | 1400 |
|------------|---|----|----|----|----|----|----|----|----|----|----|----|----|----|
| mouse      | 1 | 1  | 5  | 9  | 11 | 13 | 14 | 17 | 21 | 25 | 28 | 30 | 31 | 35 |
| eye        | 0 | 3  | 5  | 10 | 10 | 14 | 19 | 26 | 30 | 38 | 43 | 50 | 52 | 56 |
| human      | 3 | 12 | 16 | 24 | 26 | 29 | 33 | 38 | 42 | 46 | 51 | 54 | 67 | 71 |
| merged_MEH | 0 | 2  | 2  | 8  | 9  | 11 | 14 | 17 | 23 | 24 | 30 | 32 | 40 | 46 |
| merged_EH  | 0 | 1  | 3  | 6  | 8  | 9  | 10 | 11 | 14 | 19 | 23 | 26 | 30 | 33 |
| random     | 3 | 6  | 9  | 12 | 15 | 19 | 22 | 25 | 28 | 31 | 35 | 38 | 41 | 44 |

其中：

- mouse eye human 分别代表单独的三个原始数据进行训练
- merged_MEH 代表同时使用三个视图 merged_EH eye和human视图
- random 代表概率随机下的数量，可以作为一个参考

训练时间：rbr对一个数据集训练的时间基本上在20s以内，比svm快了两个数量级，所以我每次实验调参了很多次，结果是比较精确确的

因为每种视图我都做了六组实验，所以结果是比较正确的：**可以看出，
- 单独使用human数据效果最好(超越TTP的方法)
- 单独使用eye和human数据，或者三个数据一起使用的话，结果在normal之上
- 但是同时使用后两个数据，结果反而比较差
- 实验过程中，如果将基因之间的属性设置为相关，则结果会非常差**

###### 2. 使用RBR训练crx_proteomics数据

突发奇想，用rbr训练了crx的数据，虽然这数据只有五列，结果竟然非常好（前100个基因的效果比Toppgene多六个，总体持平），贝勒的数据还是特别有价值的：

| tools| top 100 | 200 | 300 | 400 | 500 | 600 | 700 | 800 | 900 | 1000 | 1100 | 1200 | 1300 | 1400 |
|------------------|----|----|----|----|----|----|----|----|----|----|-----|-----|-----|-----|
| ToppGene         | 10 | 26 | 38 | 48 | 61 | 69 | 82 | 86 | 92 | 97 | 103 | 106 | 110 | 118 |
| crx_rbr_result_1 | 16 | 26 | 35 | 44 | 56 | 68 | 75 | 81 | 85 | 92 | 98  | 107 | 112 | 115 |
| crx_rbr_result_2 | 16 | 26 | 37 | 47 | 55 | 65 | 74 | 78 | 87 | 93 | 99  | 103 | 112 | 114 |
| crx_rbr_result_3 | 9  | 14 | 17 | 20 | 20 | 25 | 29 | 33 | 36 | 42 | 53  | 54  | 57  | 61  |
| crx_rbr_result_4 | 7  | 13 | 18 | 19 | 20 | 25 | 28 | 32 | 36 | 46 | 54  | 59  | 60  | 65  |
| crx_rbr_result_5 | 6  | 13 | 18 | 19 | 21 | 25 | 28 | 32 | 36 | 46 | 54  | 59  | 60  | 63  |
| crx_rbr_result_6 | 6  | 12 | 18 | 19 | 21 | 25 | 28 | 32 | 36 | 45 | 55  | 59  | 60  | 63  |

protein_score : 8 15 32 46 50 55 60 70 79 86 92 92 93 93

注：
- 后面的结果是我通过 variable.importance （权重） 进行调参的结果，但是每次调到后面（crx_rbr_result_3后）结果都会下降得很厉害，不清楚原因
- **这个方法还是有提升空间的**

###### 3. 使用RBR训练PULP数据

数据已经找到，下载了一部分，实验正在进行中


#### 二、接下来的总体思路

- 通过各种尝试，使得我们的结果效果能更好，并超过Toppgene，目前能想到的方法
  1. 优化negative gene ，（这是周水庚老师学生的一篇论文中的核心方法），目前选的是随机选3*176 个基因作为negative ，我的想法是用一个策略（比如余弦定理）先从14177个基因中选择出一定数量的基因（比如1000个），然后从1000个基因中随机选择
  2. 优化原始数据， 我们的数据只有14177个基因，而PULP的数据更多，有17148个基因，可以借鉴
  3. 优化rbr使用策略，如果将各个view混合效果反而下降的话，根据我们的数据性质，可以考虑使用类似TTP的双层的模型，来提高结果
  4. rbr的调参还需要深入理解和提高，我可以请教王一老师
- 将方法和结果做成软件或者网站，提高文章档次，最好能输入基因名，输出它的排名及关系等


#### 三、关于Deep Learning 方法的查找

关于deep learning,我从网上查到到了一些方法，有以下十几个方法：[获取链接请点击这里](http://deeplearning.net/software_links/)

还有一个是谷歌官方出的，关于余弦定理的DeepLearning:[word2vec](http://www.csdn.net/article/2013-08-20/2816643-word2vec)

 Google开源基于Deep Learning的word2vec工具
	
